{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# deepPATH Console notebook\n",
    "\n",
    "This notebook is a collection of console commands used to tile external cohort with deeppath"
   ],
   "id": "139405530f150785"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "initial_id",
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 0.1 Tile svs slide images\n",
    "# python /path_to/0b_tileLoop_deepzoom6.py  -s 224 -e 0 -j 3 -B 40 -o <full_path_to_output_folder> \"full_path_to_input_slides/*/*svs\"\n",
    "\n",
    "\n",
    "! python \"E:\\ML_Projects\\DeepPATH\\DeepPATH_code\\00_preprocessing\\0b_tileLoop_deepzoom6.py\" -N -s 224 -e 0 -j 3 -B 40 -o \"E:\\Project\\External Cohort\\Images\\Tiles\" \"E:\\Project\\External Cohort\\Images\\Raw\\*\\*svs\"\n"
   ]
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# 0.2a split\n",
    "# MUST BE RUN FROM THE TARGET DIRECTORY!!! --> should be empty\n",
    "! python E:\\ML_Projects\\DeepPATH\\DeepPATH_code\\00_preprocessing\\0d_SortTiles_v2.py --SourceFolder=\"E:\\Project\\External Cohort\\Images\\Tiles\" --JsonFile=\"E:\\Project\\External Cohort\\classes.csv\" --Magnification=5  --MagDiffAllowed=0 --SortingOption=14 --PercentTest=15 --PercentValid=15 --nSplit 0"
   ],
   "id": "d916baf11de67f39"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Notes for 04-h5 file construction\n",
    "\n",
    "A lot of modification was made to make DeepPATH runs in serial instead of parallel, and to make them work with windows directory system.\n",
    "\n",
    "The modified `0e_jpgtoHDF.py` file can be found in the same directory as this notebook."
   ],
   "id": "8ff0e3adb5c704bd"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# 04-H5\n",
    "# IMPORTANT use chunks and sub_chunks = 1 to run in serial\n",
    "# (I don't know about sub_chunks but chunks NEEDS to be 1)\n",
    "\n",
    "! python E:\\ML_Projects\\DeepPATH\\DeepPATH_code\\00_preprocessing\\0e_jpgtoHDF.py --input_path E:\\ML_Projects\\DeepPATH\\tiles_sorted --output hdf5_EXT_he_combined.h5 --chunks 1 --sub_chunks 1 --wSize 224 --mode 2 --subset='combined'"
   ],
   "id": "332d4deec26fd65a"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
